{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"On Punjabi Version-1.ipynb","provenance":[],"collapsed_sections":["OwP8orbYHHgR","tL-8FQ3M9j3f","fq-gms85Gkn_","V28iAoEtO2a_","fg-rVqqhKTXR","XqJvyqSYL7Uf","x5VOntYZQyKd"],"mount_file_id":"1j-HiRLrnlnD0nCz0sc5DSS1RAWq0Aatm","authorship_tag":"ABX9TyNr96Xy1DjAk8oyDt4gUjei"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OwP8orbYHHgR"},"source":["## Importing Data and Libraries"]},{"cell_type":"code","metadata":{"id":"RPBlD-hr7cIf","executionInfo":{"status":"ok","timestamp":1617038174166,"user_tz":-330,"elapsed":1055,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}}},"source":["import os\n","import numpy as np\n","import string\n","from tqdm.notebook import tqdm\n","import pandas as pd\n","import tensorflow as tf\n","from tensorflow.keras import layers, Sequential, callbacks, utils"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"xnG9-or57tTG","executionInfo":{"status":"ok","timestamp":1617038174706,"user_tz":-330,"elapsed":1587,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}}},"source":["path = '/content/drive/MyDrive/Next word Generation/Data/train.txt'\n","data = ''\n","with open(path, 'r', encoding='utf-8') as file:\n","  data = file.readlines()"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tL-8FQ3M9j3f"},"source":["## Preprocessing"]},{"cell_type":"code","metadata":{"id":"ItneiCZg-9_J"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"At731dCY8ieH"},"source":["def tokenize(data, to_select_lines=-1):\n","\n","  result = []\n","  table = str.maketrans('', '', string.punctuation)\n","\n","  idx = 0\n","\n","  for line in data:\n","    line_tokens = []\n","    idx += 1\n","    if (to_select_lines == -1):\n","      idx -= 1\n","    if (idx == to_select_lines):\n","      break\n","\n","    for word in line.split():\n","      if len(word.translate(table)) > 1:\n","        line_tokens.append(word.translate(table))\n","\n","    result.append(line_tokens)\n","\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8v9g5m3O9VAx"},"source":["def create_dict(tokens, to_select_words=-1):\n","\n","  word_dict = {}\n","  for i in tokens:\n","    for j in i:\n","      try:\n","        word_dict[j] += 1\n","      except:\n","        word_dict[j] = 1\n","\n","  res_dict = {k: v for k, v in sorted(word_dict.items(), key=lambda item: item[1], reverse=True)}\n","\n","\n","  if (to_select_words == -1):\n","    final_dict = {}\n","    for idx, (key, value) in zip(range(len(res_dict)), res_dict.items()):\n","      final_dict[key] = idx\n","    return final_dict\n","\n","  final_dict = {}\n","  for idx, (key, value) in zip(range(to_select_words), res_dict.items()):\n","    final_dict[key] = idx\n","\n","  return final_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJvvQEQHAItc"},"source":["def convert(line, word_dict):\n","  result = []\n","  for word in line:\n","    try:\n","      result.append(word_dict[word])\n","    except:\n","      result.append(0)\n","\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nrL6M11c_WDa"},"source":["def get_sequences(data, word_dict, n_gram_length):\n","\n","  input_sequence = []\n","  idx = 0\n","\n","  for line in data:\n","    token_list = convert(line, word_dict)\n","    for i in range(1, len(token_list)):\n","      n_gram_seq = token_list[i:i+n_gram_length+1]\n","      if (len(n_gram_seq) == n_gram_length):\n","        input_sequence.append(n_gram_seq)\n","\n","  return input_sequence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NthuKodB8aN-"},"source":["def preprocess(data, to_select_lines=-1, to_select_words=-1, n_gram_length=3):\n","\n","  print(\"Tokenizing\")\n","  tokenized = tokenize(data, to_select_lines)\n","  print(\"Creating Dictionary\")\n","  word_dict = create_dict(tokenized, to_select_words)\n","  print(\"Creating Input Sequences\")\n","  input_sequences = get_sequences(tokenized, word_dict, n_gram_length)\n","\n","  del tokenized\n","\n","  return word_dict, input_sequences"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fq-gms85Gkn_"},"source":["## Changing data for input"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YQQq3-GeBI3O","executionInfo":{"status":"ok","timestamp":1616753594837,"user_tz":-330,"elapsed":6431,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}},"outputId":"41c8f90f-a92d-4c41-ebf4-3399923e7fc9"},"source":["word_dict, input_sequences = preprocess(data, to_select_words=10000, n_gram_length=3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Tokenizing\n","Creating Dictionary\n","Creating Input Sequences\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MMa3mkUa9FIc"},"source":["reverse_dict = {}\n","for key, value in word_dict.items():\n","  reverse_dict[value] = key"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RvuoLxS5Fqmm","executionInfo":{"status":"ok","timestamp":1616753594839,"user_tz":-330,"elapsed":6421,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}},"outputId":"b756d020-6bcd-4b2e-c842-0458945aada8"},"source":["len(input_sequences), len(word_dict)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(97614, 10000)"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vHpLloM2B8hG","executionInfo":{"status":"ok","timestamp":1616753594839,"user_tz":-330,"elapsed":6416,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}},"outputId":"660406d8-f2d6-4d24-ecf7-39ba79283364"},"source":["input_sequences = np.array(input_sequences)\n","np.random.shuffle(input_sequences)\n","input_sequences[:3]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  13,   69,   41],\n","       [  17,    0,    9],\n","       [  15, 1519,    9]])"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"IV-v8Gb3JXbg"},"source":["def data_processor(input_sequences, word_dict):\n","\n","  x = input_sequences[:, :-1]\n","  label = input_sequences[:, -1]\n","\n","  temp_array = np.zeros((label.shape[0], len(word_dict)))\n","\n","  idx=0\n","  for i in label:\n","    temp_array[idx][i] = 1\n","    idx += 1\n","\n","  return x, temp_array"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V28iAoEtO2a_"},"source":["## Saving the dictionary and sequence"]},{"cell_type":"code","metadata":{"id":"8y4yz7LRO8Rw"},"source":["a = pd.DataFrame(data = word_dict.keys())\n","a['values'] = word_dict.values()\n","a.columns = ['words', 'values']\n","a.head()\n","a.to_csv('/content/drive/MyDrive/Next word Generation/Dictionary/word_dict_1.csv', index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHbEPH5fPZyj"},"source":["np.save('/content/drive/MyDrive/Next word Generation/Sequences/seq_1.npy', input_sequences)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fg-rVqqhKTXR"},"source":["## Creating Model"]},{"cell_type":"code","metadata":{"id":"WUwjmqq2LQ9E"},"source":["def create_model(word_dict):\n","\n","  model = Sequential([\n","                    layers.Embedding(len(word_dict), 256),\n","                    layers.Bidirectional(layers.LSTM(256, return_sequences=True)),\n","                    layers.Bidirectional(layers.LSTM(256)),\n","                    layers.Dense(1024, activation='relu'),\n","                    layers.Dense(len(word_dict), activation='softmax')\n","          ])\n","  \n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XqJvyqSYL7Uf"},"source":["## Training the model"]},{"cell_type":"code","metadata":{"id":"y0gJE3vC8iRd"},"source":["def check_results(input_string, model, word_dict, reverse_dict, generation_len=10):\n","\n","  test_input = input_string\n","  next_words = generation_len\n","  table = str.maketrans('', '', string.punctuation)\n","\n","  for i in range(next_words):\n","    token_list = [w.translate(table) for w in test_input.split() if w.translate(table) != '']\n","    token_list = convert(token_list, word_dict)\n","    token_list = [token_list[-2:]]\n","    predicted =  model.predict_classes(token_list, verbose=0)[0]\n","    \n","    output_word = ''\n","    if predicted in reverse_dict:\n","      output_word = reverse_dict[predicted]\n","    test_input += \" \" + output_word\n","\n","    print(test_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b-X9BmirMXDH","executionInfo":{"status":"ok","timestamp":1616753914246,"user_tz":-330,"elapsed":311635,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}},"outputId":"fe7f4347-bed6-4033-c0df-503e0e5717a1"},"source":["model = create_model(word_dict)\n","start = 0\n","\n","for end in range(10001, len(input_sequences), 30000):\n","\n","  print(\"\\n\\n############# Iteration Start #############\\n\\n\")\n","\n","  x, y = data_processor(input_sequences[start: end], word_dict)\n","\n","  save_point = callbacks.ModelCheckpoint('/content/drive/MyDrive/Next word Generation/Models/M1.h5', monitor='loss', save_best_only=False)\n","  stop_check = callbacks.EarlyStopping(\n","                  monitor='loss', min_delta=0, patience=4, verbose=0,\n","                  mode='auto', baseline=None, restore_best_weights=False\n","                )\n","\n","  model.fit(x, y, epochs=20, callbacks=[save_point, stop_check], batch_size=256)\n","\n","  start = end\n","\n","  print(\"\\n\\n Checking Resuls \\n\\n\")\n","\n","  check_results('ਮੇਰਾ ਭਾਰਤ', model, word_dict, reverse_dict)\n","\n","  print(\"\\n\\n############# Iteration End #############\\n\\n\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","############# Iteration Start #############\n","\n","\n","Epoch 1/20\n","40/40 [==============================] - 6s 41ms/step - loss: 7.8338 - accuracy: 0.2027\n","Epoch 2/20\n","40/40 [==============================] - 2s 41ms/step - loss: 3.7615 - accuracy: 0.2292\n","Epoch 3/20\n","40/40 [==============================] - 2s 43ms/step - loss: 3.4893 - accuracy: 0.2402\n","Epoch 4/20\n","40/40 [==============================] - 2s 41ms/step - loss: 3.4495 - accuracy: 0.2384\n","Epoch 5/20\n","40/40 [==============================] - 2s 42ms/step - loss: 3.4296 - accuracy: 0.2384\n","Epoch 6/20\n","40/40 [==============================] - 2s 40ms/step - loss: 3.3165 - accuracy: 0.2588\n","Epoch 7/20\n","40/40 [==============================] - 2s 41ms/step - loss: 3.1104 - accuracy: 0.3152\n","Epoch 8/20\n","40/40 [==============================] - 2s 41ms/step - loss: 2.8362 - accuracy: 0.3650\n","Epoch 9/20\n","40/40 [==============================] - 2s 41ms/step - loss: 2.5286 - accuracy: 0.4256\n","Epoch 10/20\n","40/40 [==============================] - 2s 40ms/step - loss: 2.3864 - accuracy: 0.4464\n","Epoch 11/20\n","40/40 [==============================] - 2s 42ms/step - loss: 2.2687 - accuracy: 0.4612\n","Epoch 12/20\n","40/40 [==============================] - 2s 42ms/step - loss: 2.1307 - accuracy: 0.4754\n","Epoch 13/20\n","40/40 [==============================] - 2s 41ms/step - loss: 2.0275 - accuracy: 0.5002\n","Epoch 14/20\n","40/40 [==============================] - 2s 41ms/step - loss: 1.9410 - accuracy: 0.5098\n","Epoch 15/20\n","40/40 [==============================] - 2s 41ms/step - loss: 1.8315 - accuracy: 0.5294\n","Epoch 16/20\n","40/40 [==============================] - 2s 41ms/step - loss: 1.7602 - accuracy: 0.5428\n","Epoch 17/20\n","40/40 [==============================] - 2s 41ms/step - loss: 1.7173 - accuracy: 0.5483\n","Epoch 18/20\n","40/40 [==============================] - 2s 42ms/step - loss: 1.6218 - accuracy: 0.5624\n","Epoch 19/20\n","40/40 [==============================] - 2s 41ms/step - loss: 1.6136 - accuracy: 0.5667\n","Epoch 20/20\n","40/40 [==============================] - 2s 41ms/step - loss: 1.5568 - accuracy: 0.5740\n","\n","\n"," Checking Resuls \n","\n","\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["ਮੇਰਾ ਭਾਰਤ ਪਏ\n","ਮੇਰਾ ਭਾਰਤ ਪਏ ਹਨ\n","ਮੇਰਾ ਭਾਰਤ ਪਏ ਹਨ ਹੋਈ\n","ਮੇਰਾ ਭਾਰਤ ਪਏ ਹਨ ਹੋਈ ਹੈ।\n","ਮੇਰਾ ਭਾਰਤ ਪਏ ਹਨ ਹੋਈ ਹੈ। ਰੁਝਾਨਰਿਹਾ\n","ਮੇਰਾ ਭਾਰਤ ਪਏ ਹਨ ਹੋਈ ਹੈ। ਰੁਝਾਨਰਿਹਾ ਭਾਰੀ\n","ਮੇਰਾ ਭਾਰਤ ਪਏ ਹਨ ਹੋਈ ਹੈ। ਰੁਝਾਨਰਿਹਾ ਭਾਰੀ ਹੈ।\n","ਮੇਰਾ ਭਾਰਤ ਪਏ ਹਨ ਹੋਈ ਹੈ। ਰੁਝਾਨਰਿਹਾ ਭਾਰੀ ਹੈ। ਦੇ\n","ਮੇਰਾ ਭਾਰਤ ਪਏ ਹਨ ਹੋਈ ਹੈ। ਰੁਝਾਨਰਿਹਾ ਭਾਰੀ ਹੈ। ਦੇ ਰਹੇ।\n","ਮੇਰਾ ਭਾਰਤ ਪਏ ਹਨ ਹੋਈ ਹੈ। ਰੁਝਾਨਰਿਹਾ ਭਾਰੀ ਹੈ। ਦੇ ਰਹੇ। ਦੇ\n","\n","\n","############# Iteration End #############\n","\n","\n","\n","\n","############# Iteration Start #############\n","\n","\n","Epoch 1/20\n","118/118 [==============================] - 5s 42ms/step - loss: 2.9518 - accuracy: 0.4008\n","Epoch 2/20\n","118/118 [==============================] - 5s 41ms/step - loss: 2.3313 - accuracy: 0.4698\n","Epoch 3/20\n","118/118 [==============================] - 5s 41ms/step - loss: 2.0608 - accuracy: 0.5028\n","Epoch 4/20\n","118/118 [==============================] - 5s 41ms/step - loss: 1.8680 - accuracy: 0.5342\n","Epoch 5/20\n","118/118 [==============================] - 5s 40ms/step - loss: 1.7135 - accuracy: 0.5590\n","Epoch 6/20\n","118/118 [==============================] - 5s 40ms/step - loss: 1.5866 - accuracy: 0.5780\n","Epoch 7/20\n","118/118 [==============================] - 5s 40ms/step - loss: 1.4729 - accuracy: 0.5979\n","Epoch 8/20\n","118/118 [==============================] - 5s 40ms/step - loss: 1.3808 - accuracy: 0.6122\n","Epoch 9/20\n","118/118 [==============================] - 5s 41ms/step - loss: 1.2903 - accuracy: 0.6282\n","Epoch 10/20\n","118/118 [==============================] - 5s 41ms/step - loss: 1.2174 - accuracy: 0.6449\n","Epoch 11/20\n","118/118 [==============================] - 5s 41ms/step - loss: 1.1581 - accuracy: 0.6538\n","Epoch 12/20\n","118/118 [==============================] - 5s 41ms/step - loss: 1.0903 - accuracy: 0.6707\n","Epoch 13/20\n","118/118 [==============================] - 5s 41ms/step - loss: 1.0449 - accuracy: 0.6777\n","Epoch 14/20\n","118/118 [==============================] - 5s 40ms/step - loss: 1.0025 - accuracy: 0.6860\n","Epoch 15/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.9610 - accuracy: 0.6954\n","Epoch 16/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.9253 - accuracy: 0.7037\n","Epoch 17/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.8909 - accuracy: 0.7099\n","Epoch 18/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.8593 - accuracy: 0.7173\n","Epoch 19/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.8358 - accuracy: 0.7190\n","Epoch 20/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.8182 - accuracy: 0.7247\n","\n","\n"," Checking Resuls \n","\n","\n","ਮੇਰਾ ਭਾਰਤ ਜਾਵੇਗਾ\n","ਮੇਰਾ ਭਾਰਤ ਜਾਵੇਗਾ ਪਹੁੰਚੇ\n","ਮੇਰਾ ਭਾਰਤ ਜਾਵੇਗਾ ਪਹੁੰਚੇ ਸਨ।\n","ਮੇਰਾ ਭਾਰਤ ਜਾਵੇਗਾ ਪਹੁੰਚੇ ਸਨ। ਗਏ\n","ਮੇਰਾ ਭਾਰਤ ਜਾਵੇਗਾ ਪਹੁੰਚੇ ਸਨ। ਗਏ ਹਨ।\n","ਮੇਰਾ ਭਾਰਤ ਜਾਵੇਗਾ ਪਹੁੰਚੇ ਸਨ। ਗਏ ਹਨ। ਸਨ।\n","ਮੇਰਾ ਭਾਰਤ ਜਾਵੇਗਾ ਪਹੁੰਚੇ ਸਨ। ਗਏ ਹਨ। ਸਨ। ਦੇ\n","ਮੇਰਾ ਭਾਰਤ ਜਾਵੇਗਾ ਪਹੁੰਚੇ ਸਨ। ਗਏ ਹਨ। ਸਨ। ਦੇ ਹੈ।\n","ਮੇਰਾ ਭਾਰਤ ਜਾਵੇਗਾ ਪਹੁੰਚੇ ਸਨ। ਗਏ ਹਨ। ਸਨ। ਦੇ ਹੈ। ਦੇ\n","ਮੇਰਾ ਭਾਰਤ ਜਾਵੇਗਾ ਪਹੁੰਚੇ ਸਨ। ਗਏ ਹਨ। ਸਨ। ਦੇ ਹੈ। ਦੇ ਦੇ\n","\n","\n","############# Iteration End #############\n","\n","\n","\n","\n","############# Iteration Start #############\n","\n","\n","Epoch 1/20\n","118/118 [==============================] - 5s 40ms/step - loss: 2.1906 - accuracy: 0.5256\n","Epoch 2/20\n","118/118 [==============================] - 5s 41ms/step - loss: 1.5274 - accuracy: 0.5961\n","Epoch 3/20\n","118/118 [==============================] - 5s 41ms/step - loss: 1.2602 - accuracy: 0.6379\n","Epoch 4/20\n","118/118 [==============================] - 5s 41ms/step - loss: 1.0869 - accuracy: 0.6678\n","Epoch 5/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.9757 - accuracy: 0.6894\n","Epoch 6/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.8966 - accuracy: 0.7103\n","Epoch 7/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.8329 - accuracy: 0.7220\n","Epoch 8/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.7911 - accuracy: 0.7314\n","Epoch 9/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.7592 - accuracy: 0.7353\n","Epoch 10/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.7331 - accuracy: 0.7436\n","Epoch 11/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.7115 - accuracy: 0.7462\n","Epoch 12/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.6929 - accuracy: 0.7504\n","Epoch 13/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.6772 - accuracy: 0.7543\n","Epoch 14/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.6654 - accuracy: 0.7568\n","Epoch 15/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.6542 - accuracy: 0.7567\n","Epoch 16/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.6470 - accuracy: 0.7625\n","Epoch 17/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.6395 - accuracy: 0.7595\n","Epoch 18/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.6361 - accuracy: 0.7612\n","Epoch 19/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.6287 - accuracy: 0.7613\n","Epoch 20/20\n","118/118 [==============================] - 5s 41ms/step - loss: 0.6240 - accuracy: 0.7607\n","\n","\n"," Checking Resuls \n","\n","\n","ਮੇਰਾ ਭਾਰਤ ਸੀ।\n","ਮੇਰਾ ਭਾਰਤ ਸੀ। ਦੇ\n","ਮੇਰਾ ਭਾਰਤ ਸੀ। ਦੇ ਹੈ।\n","ਮੇਰਾ ਭਾਰਤ ਸੀ। ਦੇ ਹੈ। ਦੇ\n","ਮੇਰਾ ਭਾਰਤ ਸੀ। ਦੇ ਹੈ। ਦੇ ਸੀ।\n","ਮੇਰਾ ਭਾਰਤ ਸੀ। ਦੇ ਹੈ। ਦੇ ਸੀ। ਹੈ।\n","ਮੇਰਾ ਭਾਰਤ ਸੀ। ਦੇ ਹੈ। ਦੇ ਸੀ। ਹੈ। ਮਿਲੀ\n","ਮੇਰਾ ਭਾਰਤ ਸੀ। ਦੇ ਹੈ। ਦੇ ਸੀ। ਹੈ। ਮਿਲੀ ਸੀ।\n","ਮੇਰਾ ਭਾਰਤ ਸੀ। ਦੇ ਹੈ। ਦੇ ਸੀ। ਹੈ। ਮਿਲੀ ਸੀ। ਕੀਰਤਨ\n","ਮੇਰਾ ਭਾਰਤ ਸੀ। ਦੇ ਹੈ। ਦੇ ਸੀ। ਹੈ। ਮਿਲੀ ਸੀ। ਕੀਰਤਨ ਕੀਤਾ\n","\n","\n","############# Iteration End #############\n","\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x5VOntYZQyKd"},"source":["## Visualizing the results"]},{"cell_type":"code","metadata":{"id":"-WgjLwOcRdzS"},"source":["path = '/content/drive/MyDrive/Next word Generation/Data/train.txt'\n","data = ''\n","with open(path, 'r', encoding='utf-8') as file:\n","  data = file.readlines()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lOoBn5aNRelq","executionInfo":{"status":"ok","timestamp":1616819331054,"user_tz":-330,"elapsed":1154,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}},"outputId":"7c9f57ac-c682-4725-cb4b-2054a659a48c"},"source":["data[50:55]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"ਇਸ ਤੋਂ ਪਹਿਲਾਂ ਸਨਿਚਰਵਾਰ ਭਾਰਤ ਸਰਕਾਰ ਨੇ ਕਿਹਾ ਕਿ ਉਹ ਪਾਕਿਸਤਾਨੀ ਸੈਨਿਕਾਂ ਵਲੋਂ ਦੋ ਭਾਰਤੀ ਸੈਨਿਕਾਂ ਨੂੰ ਮਾਰ ਕੇ ਉਨ੍ਹਾਂ ਦਾ ਸਿਰ ਕਲਮ ਕਰਕੇ ਲਿਜਾਣ ਵਿਰੁੱਧ ਬਦਲੇ ਦੀ ਕਰਵਾਈ ਨਹੀਂ ਕਰੇਗਾ ਪਰ ਏਅਰ ਚੀਫ ਮਾਰਸ਼ਲ ਨਾਰਮਨ ਅਨਿਲ ਕੁਮਾਰ ਬਰਾਉਨ ਨੇ ਕਲ੍ਹ ਕਿਹਾ ਸੀ ਕਿ 2003 ਤੋਂ ਕੰਟਰੋਲ ਰੇਖਾ 'ਤੇ ਚਲੀ ਆ ਰਹੀ ਜੰਗਬੰਦੀ ਦੀ ਪਾਕਿ ਵਲੋਂ ਉਲੰਘਣਾ ਕਦੇ ਵੀ ਬਰਦਾਸ਼ਤ ਨਹੀਂ ਕੀਤੀ ਜਵੇਗੀ |\\n\",\n"," \"ਅਸੀਂ ਸਥਿਤੀ 'ਤੇ ਸਾਵਧਾਨੀ ਨਾਲ ਨਜ਼ਰ ਰੱਖ ਰਹੇ ਹਾਂ |\\n\",\n"," 'ਜੇਕਰ ਉਲੰਘਣਾ ਜਾਰੀ ਰਾਹੀ ਤਾਂ ਅਸੀਂ ਦੂਸਰੇ ਬਦਲ ਬਾਰੇ ਸੋਚਾਂਗੇ ਪਰ ਉਨ੍ਹਾਂ ਦੂਸਰੇ ਬਦਲ ਬਾਰੇ ਦੱਸਣ ਤੋਂ ਇਨਕਾਰ ਕਰ ਦਿੱਤਾ ਸੀ |\\n',\n"," \"ਜੰਮੂ ਤੇ ਕਸ਼ਮੀਰ ਵਿਚ ਭਾਰਤੀ ਫ਼ੌਜ ਵਲੋਂ ਕਥਿਤ ਰੂਪ ਵਿਚ ਕੀਤੀ ਗੋਲੀਬਾਰੀ ਵਿਚ ਪਾਕਿਸਤਾਨੀ ਸੈਨਿਕ ਦੇ ਮਾਰੇ ਜਣ ਪਿੱਛੋਂ 6 ਜਨਵਰੀ ਤੋਂ ਹੀ ਭਾਰਤ ਅਤੇ ਪਾਕਿ ਵਿਚਕਾਰ ਸਰਹੱਦ 'ਤੇ ਤਣਾਅ ਬਣਿਆਂ ਹੋਇਆ ਹੈ |\\n\",\n"," 'ਦੋ ਦਿਨ ਪਿੱਛੋਂ ਪਾਕਿ ਸੈਨਿਕ ਪੁਣਛ ਜ਼ਿਲ੍ਹੇ ਵਿਚ ਮੇਂਧਰ ਸੈਕਟਰ ਵਿਚ ਦੋ ਭਾਰਤੀ ਸੈਨਿਕਾਂ ਦਾ ਸਿਰ ਵੱਢ ਕੇ ਲੈ ਗਏ |\\n']"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"WJDH13w6O7Gl"},"source":["df = pd.read_csv('/content/drive/MyDrive/Next word Generation/Dictionary/word_dict_1.csv')\n","model = tf.keras.models.load_model('/content/drive/MyDrive/Next word Generation/Models/M1.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VEUHJmumQ7_p"},"source":["word_dict = {}\n","for i,j in zip(df['words'], df['values']):\n","  word_dict[i] = j"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zp38XdggRSLY"},"source":["reverse_dict = {}\n","for key, value in word_dict.items():\n","  reverse_dict[value] = key"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iHhXZm2jRXQp"},"source":["table = str.maketrans('', '', string.punctuation)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zrQy3IOxRAuI"},"source":["def convert(line, word_dict):\n","  result = []\n","  for word in line:\n","    try:\n","      result.append(word_dict[word])\n","    except:\n","      result.append(0)\n","  return result"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b0NVOroGRZoQ","executionInfo":{"status":"ok","timestamp":1616818926463,"user_tz":-330,"elapsed":1698,"user":{"displayName":"Abhishek Prajapat","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg604IENiNVEYoc-U-T5E_szulyEzqDfmtw1_Gu=s64","userId":"04077743234157551972"}},"outputId":"67cb0d97-d903-4365-8a58-e611cbada845"},"source":["test_input = 'ਉਹ ਕਰੇਗਾ'\n","next_words = 10\n","array = np.zeros((10, len(word_dict)))\n","\n","for i in range(next_words):\n","  token_list = [w.translate(table) for w in test_input.split() if w.translate(table) != '']\n","  token_list = convert(token_list, word_dict)\n","  token_list = [token_list[-2:]]\n","  array[i] = model.predict(token_list, verbose=0)[0]\n","  predicted =  model.predict_classes(token_list, verbose=0)[0]\n","  output_word = ''\n","  if predicted in reverse_dict:\n","    output_word = reverse_dict[predicted]\n","  test_input += \" \" + output_word\n","\n","  print(test_input)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["ਉਹ ਕਰੇਗਾ ਦੇ\n","ਉਹ ਕਰੇਗਾ ਦੇ ਗਏ।\n","ਉਹ ਕਰੇਗਾ ਦੇ ਗਏ। ਦੇ\n","ਉਹ ਕਰੇਗਾ ਦੇ ਗਏ। ਦੇ ਹੈ।\n","ਉਹ ਕਰੇਗਾ ਦੇ ਗਏ। ਦੇ ਹੈ। ਦੇ\n","ਉਹ ਕਰੇਗਾ ਦੇ ਗਏ। ਦੇ ਹੈ। ਦੇ ਸੀ।\n","ਉਹ ਕਰੇਗਾ ਦੇ ਗਏ। ਦੇ ਹੈ। ਦੇ ਸੀ। ਹੈ।\n","ਉਹ ਕਰੇਗਾ ਦੇ ਗਏ। ਦੇ ਹੈ। ਦੇ ਸੀ। ਹੈ। ਮਿਲੀ\n","ਉਹ ਕਰੇਗਾ ਦੇ ਗਏ। ਦੇ ਹੈ। ਦੇ ਸੀ। ਹੈ। ਮਿਲੀ ਸੀ।\n","ਉਹ ਕਰੇਗਾ ਦੇ ਗਏ। ਦੇ ਹੈ। ਦੇ ਸੀ। ਹੈ। ਮਿਲੀ ਸੀ। ਕੀਰਤਨ\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"prwyP55eRqvo"},"source":[""],"execution_count":null,"outputs":[]}]}